---
title: 딥네트워크
category:
  - AI
tags:
 - [Aiffel, DL]
Date: 2023-07-03
Last_modified_at: 2023-07-04
---





# 딥네트워크

- AlexNet
- VGG
  - 3 x 3 커널을 사용하여 더 많은 레이어를 쌓고 이미지의 비선형적 특징을 더 잘 잡아낼 수 있도록 함.
  - 이미지의 output size가 동일하다고 가정했을 때 작은 필터를 여러개 쌓는 것이 적은 parameter를 가지므로 더 효율적이다. 

- ResNet

  - vanishing/exploding gradient 해결

  - skip connection

    - 레이어의 입력을 다른 곳에 이어서 gradient가 깊은 곳까지 이어지도록 한다

    - [ResNets(Andrew Ng)](https://youtu.be/ZILIbUvp5lk)

    - skip connection을 사용하는 다른 네트워크

      - DenseNet

      - U-net

        

### Vanishing gradient

- 모델이 깊어질수록 모델 학습을 위한 gradient가 사라지는 현상
- 가중치가 여러 번 곱해지다 보면 gradient가 너무 작아져 Vanishing gradient(기울기 소실, 경사 소실)이 일어나거나 너무 커져 exploding gradient(기울기 폭주)가 일어난다.
- [Vanishing/exploding gradients(Andrew Ng)](https://youtu.be/qhXZsFVxGKo)



## Model API

- TensorFlow
  - [TensorFlow models repository](https://github.com/tensorflow/models)
  - pre-trained model들은 slim이라는 고수준 API로 구현되어 있다.
- Keras
  - [Keras applications docs](https://www.tensorflow.org/api_docs/python/tf/keras/applications)
  - [Keras applications](https://github.com/keras-team/keras-applications)

