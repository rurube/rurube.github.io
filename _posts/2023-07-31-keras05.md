---
title: 머신 러닝의 기본 요소
category: AI
tags:
  - [DL, 케창딥]
date: 2023-07-31
math: true
---

## 5.1 일반화: 머신 러닝의 목표

- 최적화(optimization): 가능한 훈련 데이터에서 최고의 성능을 얻기 위해 모델을 조정하는 과정
- 일반화(generalization): 훈련된 모델이 새로운 데이터에서 얼마나 잘 수행되는지 의미
- 머신 러닝의 목표는 **좋은 일반화 성능**을 얻는 것



### 5.1.1 과소적합과 과대적합

- 과소적합
  - 훈련 초기에 훈련 손실이 낮아질수록 검증 손실이 함께 낮아지는 구간
  - 모델 성능이 발전될 여지가 있음
  - 훈련 데이터에 있는 패턴을 모두 학습하지 못함
- 과대적합
  - 훈련을 일정 이상 반복한 후 검증 세트의 성능이 멈추고 감소되기 시작하는 구간
  - 훈련 데이터에 **특화된** 패턴을 학습하기 시작함
  - 데이터에 **잡음**이 있거나, **불확실성**이 존재하거나, **드문 특성**이 포함되어 있을 때 발생하기 쉬움
    - 잡음 섞인 훈련 데이터: 잘못된 입력, 잘못된 레이블
    - 불확실한 특성: 범주에 객관적 경계가 없는 **모호성**, 같은 데이터에 다른 결과가 따를 수 있는 **무작위성**
    - 드문 특성과 가짜 상관관계: 특성이 드물면 모델이 특성을 잘못 판단할 수 있고, 잘못된 추측으로 인해 실제로는 관련이 없는 가짜 상관관계가 생길 수도 있다.
  - 잡음 제거를 위해 특성 선택(feature selection)을 진행할 수 있음



### 5.1.2 딥러닝에서 일반화의 본질

- 매니폴드 가설
  - 매니폴드란 선형 공간과 비슷하게 보이는 부모 공간의 저차원 부분 공간이다.
  - **매니폴드 가설(manifold hypothesis)**은 실제 세상의 모든 데이터가 고차원 공간 안에 있는 저차원 매니폴드에 놓여 있다고 가정한다
  - 매니폴드 가설은 다음을 의미한다
    - 머신 러닝 모델은 입력 공간 안에서 비교적 간단하고, 저차원이며, 매우 구조적인 부분 공간(잠재 매니폴드(latent manifold))만 학습하면 된다
    - 이런 매니폴드 중 하나 안에서 두 입력 사이를 보간(interpolation)하는 것이 항상 가능하다. 즉, 연속적인 경로를 따라 한 입력에서 다른 입력으로 변형할 때 모든 포인트가 매니폴드에 속한다.
- 일반화의 원천인 보간
  - 다루는 데이터 포인트가 보간 가능하다면 새로운 포인트를 해당 매니폴드에서 가까이 놓인 다른 포인트와 연결하여 이해할 수 있다
  - 보간을 사용해 빈 곳을 채움으로써 공간 안의 샘플만으로 공간 전체를 이해할 수 있다
  - 지역 일반화(local generalizaion): 이전에 본 것과 매우 가까운 것을 이해하는 것
  - 궁극 일반화(extreme generalization): 사람이 일반화하는 방법으로, 보간 이외의 인지 매커니즘을 사용한다. 인지 매커니즘은 추상화, 세상에 대한 상징적 모델, 추론, 논리, 상식, 이성으로 불리는 세상에 대한 선천적 능력 등을 말한다.
- 딥러닝이 작동하는 이유
  - 데이터를 구겨진 종이 공으로 비유하면, 펴진 종이는 2D 매니폴드를 나타내고 딥러닝은 구겨진 종이 공을 펼치는 도구이다
  - 딥러닝은 근본적으로 미분 가능한 곡선으로 경사 하강법을 통해 이 곡선을 데이터 포인트에 맞춘다
    - 크고 복잡한 곡선(매니폴드)을 선택하여 훈련 데이터 포인트에 맞을 때까지 파라미터를 점진적으로 조정한다
    - 데이터는 입력 공간 안에서 고도로 구조적인 저차원 매니폴드를 형성(매니폴드 가설)하고, 경사 하강법으로 모델 곡선을 이 데이터에 맞추면 모델이 데이터의 매니폴드를 대략적으로 근사하는 중간 지점을 찾을 수 있다.
  - 딥러닝 모델이 잠재 매니폴드를 학습하는 데 특히 잘 맞는 속성들이 있다
    - 모델의 매끄러움은(미분 가능성) 동일 속성을 가진 잠재 매니폴드를 근사하는 데에 도움이 된다
    - 딥려닝 모델은 훈련 데이터의 정보 형태를 반영하는 식으로 구조화되는데, 이는 자연적인 데이터가 구성되는 방식을 반영한 것이다
- 가장 중요한 훈련 데이터
  - 일반화의 능력은 모델의 속성보다는 데이터의 구조에 의한 결과이다. 즉, 데이터가 보간할 수 있는 매니폴드를 형성할 수 있어야 한다
    - 특성이 유익하고 잡음이 적을수록 입력 공간이 간단하고 구조적이기 때문에 일반화 성능이 좋다
    - 따라서 데이터 큐레이션(data curation)과 특성 공학(feature engineering)이 필수적이다
  - 모델이 곡선을 맞추는 것을 잘 수행하기 위해, 특히 결정 경계 근처에서, 입력 데이터 매니폴드 전체를 조밀하게 커버해야 한다. 충분히 조밀하게 샘플링하면 외부 지식 없이도 훈련 입력 사이를 보간하여 새로운 입력을 이해할 수 있게 된다.(일반화)
  - 결과적으로 딥러닝 모델을 향상시키는 가장 좋은 방법은 더 좋고, 더 많은 데이터에서 훈련하는 것이다
    - 만약 데이터를 더 수집하는 것이 불가능하다면, 제약을 추가할 수 있고 이를 **규제(regularizaion)**라고 부른다.



## 5.2 머신 러닝 모델 평가

### 5.2.1 훈련, 검증, 테스트 세트

- **훈련 세트**에서 모델을 훈련하고 검증 세트에서 모델을 평가한다. 그리고 모델이 완성된 후 **테스트 세트**를 통해 모델을 테스트한다.
- 검증 세트를 사용하는 이유
  - 검증 세트에서 평가하는 모델의 성능을 바탕으로 **하이퍼 파라미터 튜닝**을 수행한다
  - 그러나 튜닝도 학습의 일종으로 여러 번 반복할 경우 **정보 누설(information leak, 검증 데이터의 정보가 누설되는 것)**을 야기한다
- 모델은 테스트 세트에 대한 어떤 정보도 얻어서는 안 된다. 이는 일반화 성능을 왜곡시킨다.
- **단순 홀드아웃 검증(hold-out validation), K-겹 교차 검증(K-fold cross-validation), 셔플링(Shuffling)을 사용한 반복 K-겹 교차 검증(iterated K-fold cross-validation)**과 같은 기법을 사용할 수 있다.



#### 단순 홀드아웃 검증

- 데이터의 일정량을 테스트 세트로 떼어 놓고, 검증 세트도 따로 떼어 놓는다
- 주로 사이킷런의 train_test_split() 함수를 사용한다
- 이 방법은 단순하지만 데이터가 적을 때 검증 세트의 샘플 크기가 너무 작아 주어진 전체 데이터를 **통게적으로 대표하지 못할 수도 있다**는 단점이 있다

![holdout-validation](https://github.com/rurube/rurube.github.io/assets/81694385/4d3aca47-73dd-46a6-b3d6-048c6174fe14)



#### K-겹 교차 검증

- 데이터를 동일한 크기를 가진 K개의 분할로 나누고, 각 분할에 대해 남은 분할로 모델을 훈련하고 해당 분할에서 모델을 평가한다. 최종 점수는 이렇게 얻은 K개의 점수의 평균이다.
- 모델의 성능이 데이터 분할에 따라 편차가 클 때 도움이 된다

![kfold-crossvalidation](https://github.com/rurube/rurube.github.io/assets/81694385/1d3333a9-3379-4887-9f53-98ec7a9119ec)



#### 셔플링을 사용한 반복 K-겹 교차 검증

- 가용 데이터가 적고 정확하게 모델을 평가하고자 할 때 사용한다
- K-겹 교차 검증을 여러 번 적용하되, K개의 분할로 나누기 전에 매번 데이터를 무작위로 섞는다. 최종 점수는 모든 교차 검증을 실행해서 얻은 점수의 평균이다. 
- $반복 횟수\times K$개의 모델을 훈련하고 평가하므로 비용이 매우 많이 든다